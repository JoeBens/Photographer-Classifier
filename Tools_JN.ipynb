{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dir_sc, images_per_class=None):\n",
    "    inames = []\n",
    "    ilabels = []\n",
    "    cnames = sorted(os.listdir(dir_sc))\n",
    "    for ilabel, cl in enumerate(cnames):\n",
    "        dir_cl = os.path.join(dir_sc, cl)\n",
    "        for iname in os.listdir(dir_cl)[:images_per_class]:\n",
    "            inames.append(os.path.join(cl, iname))\n",
    "            ilabels.append(ilabel)\n",
    "    ilabels = np.array(ilabels)\n",
    "    return inames, ilabels, cnames\n",
    "\n",
    "def ComputeHoG(im, show = False):\n",
    "    fd, hog_image = hog(im, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True)\n",
    "    if show == True:\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "        ax1.axis('off')\n",
    "        ax1.imshow(im, cmap=plt.cm.gray)\n",
    "        ax1.set_title('Input image')\n",
    "\n",
    "        # Rescale histogram for better display\n",
    "        hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "        ax2.axis('off')\n",
    "        ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "        ax2.set_title('Histogram of Oriented Gradients')\n",
    "        plt.show()\n",
    "\n",
    "    return fd, hog_image\n",
    "\n",
    "def resize_image(img, shape = (1024,1024)):\n",
    "    return cv.resize(img, shape, interpolation =cv.INTER_LINEAR)\n",
    "\n",
    "def ComputeHoGs(inames):\n",
    "\n",
    "    Hogs = []\n",
    "    features = []\n",
    "    for i, x in tqdm.tqdm(enumerate(inames)):\n",
    "        p = os.path.join(path, x)\n",
    "        img = cv.imread(p)\n",
    "        gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        gray = resize_image(gray)\n",
    "        feature, hog = ComputeHoG(gray)\n",
    "        Hogs.append(hog)\n",
    "        features.append(feature)\n",
    "    \n",
    "    return features, Hogs\n",
    "\n",
    "\n",
    "def ComputeSift_CV(I):\n",
    "    gray= cv.cvtColor(I,cv.COLOR_BGR2GRAY)\n",
    "    sift = cv.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray,None)\n",
    "    img = cv.drawKeypoints(gray,kp,I,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    return kp, des\n",
    "\n",
    "def ComputeSiftDataset_CV(inames):\n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    for x in tqdm.tqdm(inames):\n",
    "        p = os.path.join(path, x)\n",
    "        img = cv.imread(p)\n",
    "        kp, des = ComputeSift_CV(img)\n",
    "        keypoints.append(kp)\n",
    "        descriptors.append(des)\n",
    "    \n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "def compute_split(length, seed=1337, pc=0.80):\n",
    "    train_ids = np.random.RandomState(seed=seed).choice(\n",
    "        length,\n",
    "        size=int(length * pc),\n",
    "        replace=False)\n",
    "    test_ids = np.array(list(set(np.arange(length)) - set(train_ids)))\n",
    "    return train_ids, test_ids\n",
    "\n",
    "\n",
    "def compute_visual_dict(sift, n_clusters=1000, n_init=1, verbose=1):\n",
    "    # reorder data\n",
    "    dim_sift = sift[0].shape[-1]\n",
    "    sift = [s.reshape(-1, dim_sift) for s in sift]\n",
    "    sift = np.concatenate(sift, axis=0)\n",
    "    # remove zero vectors\n",
    "    keep = ~np.all(sift==0, axis=1)\n",
    "    sift = sift[keep]\n",
    "    # randomly pick sift\n",
    "    ids, _ = compute_split(sift.shape[0], pc=0.05)\n",
    "    sift = sift[ids]\n",
    "\n",
    "    zeros_vect = np.zeros((128))\n",
    "    kmeans = KMeans(n_clusters=n_clusters).fit(sift)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    np.append(centers, zeros_vect)\n",
    "    vdict = centers\n",
    "\n",
    "    return vdict\n",
    "\n",
    "\n",
    "\n",
    "def display_images(images):\n",
    "    n_images,w,h = images.shape\n",
    "    n = int(np.ceil(np.sqrt(n_images)))\n",
    "    im = np.zeros((n*w, n*h))\n",
    "    for k in range(n_images):\n",
    "        i = k % n\n",
    "        j = k // n\n",
    "        im[i*w:i*w+w, j*h:j*h+h] = images[k]\n",
    "\n",
    "    plt.figure(figsize=(0.7*n,0.7*n))\n",
    "    plt.gray()\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def dense_sampling(im, s=8):\n",
    "    w, h = im.shape\n",
    "    x = np.arange(0, w, s)\n",
    "    y = np.arange(0, h, s)\n",
    "    return x, y\n",
    "\n",
    "def auto_padding(im, k=16, s=8):\n",
    "    w, h = im.shape\n",
    "    x = np.arange(0, w, s)\n",
    "    y = np.arange(0, h, s)\n",
    "    # last region could be smaller\n",
    "    last_r = im[x[-1]:x[-1]+k, y[-1]:y[-1]+k]\n",
    "    if last_r.shape == (k, k):\n",
    "        return im\n",
    "    dif_w = k - last_r.shape[0]\n",
    "    dif_h = k - last_r.shape[1]\n",
    "    n_im = np.zeros((w+dif_w, h+dif_h))\n",
    "    id_w = dif_w // 2\n",
    "    id_h = dif_h // 2\n",
    "    n_im[id_w:id_w+w, id_h:id_h+h] = im\n",
    "    return n_im\n",
    "\n",
    "\n",
    "def conv_separable(im, h_x, h_y, pad=1):\n",
    "    h_x = h_x.reshape(1,3)\n",
    "    h_y = h_y.reshape(3,1)\n",
    "\n",
    "    im_w, im_h = im.shape\n",
    "    hx_w, hx_h = h_x.shape\n",
    "    hy_w, hy_h = h_y.shape\n",
    "\n",
    "    h_x_t = h_x.transpose()\n",
    "    h_y_t = h_y.transpose()\n",
    "\n",
    "    if hx_w != 1:\n",
    "        raise ValueError()\n",
    "    if hx_h % 2 != 1:\n",
    "        raise ValueError()\n",
    "    if hy_h != 1:\n",
    "        raise ValueError()\n",
    "    if hy_w % 2 != 1:\n",
    "        raise ValueError()\n",
    "    if hx_h != hy_w:\n",
    "        raise ValueError()\n",
    "        \n",
    "        \n",
    "def gaussian_mask(size=16, sigma=0.5):\n",
    "    sigma *= size\n",
    "    ax = np.arange(-size // 2 + 1., size // 2 + 1.)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2. * sigma**2))\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "\n",
    "def compute_grad(I):\n",
    "\n",
    "    gX = cv.Sobel(I, ddepth=cv.CV_32F, dx=1, dy=0, ksize=3)\n",
    "    gY = cv.Sobel(I, ddepth=cv.CV_32F, dx=0, dy=1, ksize=3)\n",
    "    #print(gX)\n",
    "    #print(gY)\n",
    "    return gX, gY\n",
    "\n",
    "def compute_grad_ori(g_x, g_y, g_m, b=8):\n",
    "    ori = np.zeros((b, 2))\n",
    "    for i in range(b):\n",
    "        ori[i,0] = np.cos(2 * np.pi * i / b)\n",
    "        ori[i,1] = np.sin(2 * np.pi * i / b)\n",
    "    w, h = g_m.shape\n",
    "    # TODO: algebraic form\n",
    "    g_o = np.zeros((w, h))\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            if g_m[i,j] > 0:\n",
    "                v = np.array([g_y[i,j], -g_x[i,j]])\n",
    "                v = v / np.linalg.norm(v, ord=2)\n",
    "                prod = np.dot(ori,v)\n",
    "                g_o[i,j] = np.argmax(prod)\n",
    "            else:\n",
    "                g_o[i,j] = -1\n",
    "    g_o = g_o.astype(int)\n",
    "    return g_o\n",
    "\n",
    "\n",
    "def compute_grad_mod_ori(I):\n",
    "\n",
    "\n",
    "    Ix, Iy = compute_grad(I)\n",
    "\n",
    "    Gn = np.sqrt(Ix**2 + Iy**2)\n",
    "    Go = compute_grad_ori(Ix, Iy, Gn, 8)#np.arctan(Iy/Ix)\n",
    "    return Gn, Go\n",
    "\n",
    "def compute_histogram(g_n, g_o):\n",
    "    \"\"\"\n",
    "    g_n and g_o are 4x4 matrices that contain the norm, and the discretized orientation.\n",
    "    \"\"\"\n",
    "    hist = np.zeros((8))\n",
    "    for i in range(8):\n",
    "        hist[i] = g_n[g_o == i].sum()\n",
    "    return hist\n",
    "\n",
    "\n",
    "\n",
    "def compute_sift_region(Gn, Go, mask=None):\n",
    "    t_min=.5\n",
    "    t_max=.2\n",
    "    with_l2 = True\n",
    "\n",
    "    patch_size = 16\n",
    "    sift = np.zeros((128)) \n",
    "\n",
    "    if mask is not None:\n",
    "        Gn = Gn * mask\n",
    "    \n",
    "    idx = 0\n",
    "    for k in range(0, patch_size, 4):\n",
    "        for l in range(0, patch_size, 4):\n",
    "            hist = compute_histogram(Gn[l:l+4,k:k+4], Go[l:l+4,k:k+4])            \n",
    "            sift[idx:idx+8] = hist\n",
    "            idx += 8\n",
    "\n",
    "    norm = np.linalg.norm(sift, ord=2)\n",
    "    # min thresholding on norm\n",
    "    if norm <= t_min:\n",
    "        return np.zeros((128))\n",
    "    # l2-normalization\n",
    "    if with_l2:\n",
    "        sift = sift / norm\n",
    "    # max thresholding on values\n",
    "    sift[sift >= t_max] = t_max\n",
    "    # l2-normalization\n",
    "    if with_l2:\n",
    "        norm = np.linalg.norm(sift, ord=2)\n",
    "        sift = sift / norm\n",
    "    return sift\n",
    "\n",
    "def compute_sift_image(I):\n",
    "    x, y = dense_sampling(I)\n",
    "    im = auto_padding(I)\n",
    "    m = gaussian_mask()\n",
    "    \n",
    "    # Here, compute on the global image (norm, gradients)\n",
    "    Gn, Go = compute_grad_mod_ori(I)\n",
    "    \n",
    "    sifts = np.zeros((len(x), len(y), 128))\n",
    "    for i, xi in enumerate(x):\n",
    "        for j, yj in enumerate(y):\n",
    "            if xi + 16 <= Gn.shape[0] and yj + 16 <= Gn.shape[1]:  # it was usefull afterall\n",
    "                sifts[i, j, :] = compute_sift_region(Gn[xi:xi+16, yj:yj+16], Go[xi:xi+16, yj:yj+16], m) # TODO SIFT du patch de coordonnee (xi, yj)\n",
    "    return sifts\n",
    "\n",
    "def ComputeSiftDataset(inames):\n",
    "\n",
    "    descriptors = []\n",
    "    for x in tqdm.tqdm(inames):\n",
    "        p = os.path.join(path, x)\n",
    "        img = cv.imread(p)\n",
    "        gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        gray = resize_image(gray)\n",
    "        #print(gray.shape)\n",
    "        des = compute_sift_image(gray)\n",
    "        des = (des * 255).astype('uint8')\n",
    "        descriptors.append(des)\n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "def compute_regions(im, k=16, s=8):\n",
    "    x, y = dense_sampling(im) # before padding\n",
    "    im = auto_padding(im)\n",
    "    images = np.zeros((x.shape[0], y.shape[0], k, k))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[0]):\n",
    "            images[i,j] = im[x[i]:x[i]+k, y[j]:y[j]+k]\n",
    "    return images\n",
    "\n",
    "\n",
    "def get_regions(inames):\n",
    "    vdpaths = [os.path.join(path, iname) for iname in inames]\n",
    "\n",
    "    regions = []\n",
    "    for p in vdpaths:\n",
    "        im = cv.imread(p)\n",
    "        gray= cv.cvtColor(im,cv.COLOR_BGR2GRAY)\n",
    "        regions.append(compute_regions(gray))\n",
    "\n",
    "    k = regions[0].shape[-1]\n",
    "    n_reg = np.array([r.shape[0]*r.shape[1] for r in regions])\n",
    "    cs_reg = np.cumsum(n_reg)\n",
    "\n",
    "    regions = [r.reshape(-1, k, k) for r in regions]\n",
    "    regions = np.concatenate(regions, axis=0)\n",
    "\n",
    "    return regions\n",
    "\n",
    "\n",
    "def compute_feats(vdict, descriptors):\n",
    "    \"\"\"\n",
    "    vdict: (num_clusters, 128): visual dictionnary containing all clusters.\n",
    "    image_sifts: (H, W, 128) all sift features from the given image\n",
    "    \"\"\"\n",
    "    # flatten sifts\n",
    "    sifts = np.array(descriptors).reshape(-1, 128)  # (N, 128)\n",
    "    #print(sifts.shape)\n",
    "    feats = np.zeros(vdict.shape[0])\n",
    "    \n",
    "    distances = distance_matrix(sifts, vdict)\n",
    "    best_feature = np.argmin(distances, axis=1)\n",
    "    for i in best_feature:\n",
    "      feats[i]+=1\n",
    "    \n",
    "    norm = np.linalg.norm(feats, ord=2)\n",
    "    feats = feats/norm\n",
    "    return feats\n",
    "\n",
    "\n",
    "def ComputeLaplacian(img):\n",
    "    \n",
    "    src = cv.GaussianBlur(img, (3, 3), 0)\n",
    "    gray= cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "    dst = cv.Laplacian(gray, ddepth, ksize=kernel_size)\n",
    "    gray = resize_image(dst, shape = (512,512))\n",
    "    abs_dst = cv.convertScaleAbs(gray)\n",
    "\n",
    "    return abs_dst\n",
    "\n",
    "\n",
    "def ComputeLaplacians(inames):\n",
    "    laplacians = []\n",
    "    for x in tqdm.tqdm(inames):\n",
    "        p = os.path.join(path, x)\n",
    "        img = cv.imread(p)\n",
    "        laplacian = ComputeLaplacian(img)\n",
    "        laplacian = np.ravel(laplacian)\n",
    "        laplacians.append(laplacian)\n",
    "    return laplacians"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
